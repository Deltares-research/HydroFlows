{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rio de Janeiro flood risk assessment using global data\n",
    "\n",
    "This notebook presents a workflow for assessing pluvial flood risk for the Acari River Basin under different climate scenarios with **HydroFlows** using solely global data sources. This notebook can serve as a guide for conducting a flood risk assessment in a different region if needed without using any local sources. If local sources are available, they can be easily integrated into the workflows; in this case, the user is referred to the `rio_risk_climate_strategies` notebook.\n",
    "\n",
    "To develop a comprehensive flood risk assessment, we created hazard (SFINCS) and impact (FIAT) models using only global datasets. Global re-analysis data (ERA5) was used to generate design events for different return periods. These events were then **scaled using climate change (CC) scaling techniques** to simulate future climate conditions. The study considers three climate scenarios:  \n",
    "- The **Present (Historical)** scenario with no temperature change.  \n",
    "- A **Moderate Emissions (RCP4.5, 2050)** scenario with a projected temperature increase of **+1.2°C**.  \n",
    "- A **High Emissions (RCP8.5, 2050)** scenario with a projected temperature increase of **+2.5°C**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pathlib import Path\n",
    "\n",
    "from hydroflows import Workflow, WorkflowConfig\n",
    "from hydroflows.log import setuplog\n",
    "from hydroflows.methods import fiat, rainfall, sfincs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder Structure  \n",
    "\n",
    "The folder structure remains the same as in the `rio_risk_climate_strategies` notebook. Below is an overview of the key components:  \n",
    "\n",
    "1. Model Executables (`bin/`)  \n",
    "The `bin/` directory stores the executable files required to run the models, namely **SFINCS** and **FIAT**  \n",
    "\n",
    "2. Data Directory (`data/`)  \n",
    "All input and processed data are stored within this directory. It contains the following subfolders:  \n",
    "\n",
    "- `global-data/`: Stores global datasets, with a corresponding `data_catalog.yml` file documenting the required sources and paths.  \n",
    "- `local-data/`: Contains local datasets, also accompanied by a `data_catalog.yml` file for reference.  \n",
    "- `preprocessed-data/`: Stores datasets generated through preprocessing of local or global data. The preprocessing script automatically generates a `data_catalog.yml` file (shown later in the workflow).  \n",
    "\n",
    "3. Scripts Directory (`scripts/`)  \n",
    "This folder contains Python scripts used for data preprocessing and analysis.\n",
    "\n",
    "4. Model Setups (`setups/`)  \n",
    "The `setups/` directory is divided into two subfolders, `global/` and `local/`, representing different modelling configurations for the Acari basin (in this noteboook only local). In the setup directories the built models as well as their output will be saved by case. Each setup contains a `hydromt_config/` folder where configuration files for **HydroMT** are stored.  The `local/` setup includes specific configuration files for the **SFINCS** model, corresponding to different adaptation strategies, and also the configuration file for the **FIAT** model:  \n",
    "  - `sfincs_config_default.yml` (current system state)  \n",
    "  - `sfincs_config_reservoirs.yml` (planned reservoirs)  \n",
    "  - `sfincs_config_dredging.yml` (dredging scenario)  \n",
    "  - `fiat_config.yml`\n",
    "\n",
    "Overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Rio\n",
    "├── bin\n",
    "│   ├── fiat_v0.2.1\n",
    "│   └── sfincs_v2.1.1\n",
    "├── data\n",
    "│   ├── global-data\n",
    "│   │   └── data_catalog.yml\n",
    "│   ├── local-data\n",
    "│   │   └── data_catalog.yml\n",
    "│   ├── preprocessed-data\n",
    "│   │   └── data_catalog.yml\n",
    "│   └── region.gpkg\n",
    "├── scripts\n",
    "├── setups\n",
    "│   ├── global\n",
    "│   │   └── hydromt_config\n",
    "│   └── local\n",
    "│       └── hydromt_config\n",
    "│           ├── sfincs_config_default.yml\n",
    "│           ├── sfincs_config_reservoirs.yml\n",
    "│           ├── sfincs_config_dredging.yml\n",
    "│           └── fiat_config.yml\n",
    "├── rio_risk_climate_strategies.ipynb\n",
    "└── rio_risk_climate_with_global_data.ipynb (this notebook)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook only sources corresponding to global data are used, namely `data/global-data/` and `setups/global`. No scripts are used, as there is no pre-processing of local data involved. Additionally, no strategies are included, as they are considered \"local\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define case name, root directory and logger\n",
    "\n",
    "pwd = Path().resolve() # current directory\n",
    "name = \"global-risk-climate\"\n",
    "setup_root = Path(pwd, \"setups\", \"global\")\n",
    "pwd_rel = \"../../\"  # relative path from the case directory to the current file\n",
    "\n",
    "# Setup the logger\n",
    "logger = setuplog(level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the workflow\n",
    "\n",
    "In this block the workflow configuration is specified and a HydroFlows workflow is created. The workflow takes as input the following:\n",
    "- the region polygon of the Acari river basin\n",
    "- the global data catalog file describing all the input datasets\n",
    "- the HydroMT configuration file\n",
    "- the model executables\n",
    "\n",
    "In addition some more general settings are specified that are used in the methods below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the config file\n",
    "config = WorkflowConfig(\n",
    "    # general settings\n",
    "    region=Path(pwd, \"data/region.geojson\"),\n",
    "    catalog_path=Path(pwd, \"data/global-data/data_catalog.yml\"),\n",
    "    plot_fig=True,\n",
    "    # sfincs settings\n",
    "    hydromt_sfincs_config=Path(setup_root, \"hydromt_config/sfincs_config_default.yml\"),\n",
    "    sfincs_exe=Path(pwd, \"bin/sfincs_v2.1.1/sfincs.exe\"),\n",
    "    depth_min=0.05,\n",
    "    subgrid_output=True,  # sfincs subgrid output should exist since it is used in the fiat model\n",
    "    # fiat settings\n",
    "    hydromt_fiat_config=Path(setup_root, \"hydromt_config/fiat_config.yml\"),\n",
    "    fiat_exe=Path(pwd, \"bin/fiat_v0.2.1/fiat.exe\"),\n",
    "    risk=True,\n",
    "    # design events settings\n",
    "    rps=[5, 10, 100],\n",
    "    start_date=\"1990-01-01\",\n",
    "    end_date=\"2023-12-31\",\n",
    "    # Climate rainfall scenarios settings (to be applied on the derived design events)\n",
    "    # Dictionary where:\n",
    "    # - Key: Scenario name (e.g., \"current\", \"rcp45\", \"rcp85\")\n",
    "    # - Value: Corresponding temperature delta (dT) for each scenario\n",
    "    scenarios_dict={\n",
    "        \"present\": 0,  # No temperature change for the present (or historical) scenario\n",
    "        \"rcp45_2050\": 1.2,  # Moderate emissions scenario with +1.2°C\n",
    "        \"rcp85_2050\": 2.5,  # High emissions scenario with +2.5°C\n",
    "    },\n",
    ")\n",
    "\n",
    "w = Workflow(config=config, name=name, root=setup_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Hazard and Impact models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method builds the SFINCS model for the Acari River Basin. It takes as input the region geometry, the HydroMT configuration file and the global data catalog and it generates SFINCS model saved in the models dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SFINCS model for the Acari river basin\n",
    "# - settings from the hydromt_config \n",
    "# - data from the global data catalog\n",
    "\n",
    "# Note that subgrid_output is set to True, since the subgrid output is used in the fiat model\n",
    "sfincs_build = sfincs.SfincsBuild(\n",
    "    region=w.get_ref(\"$config.region\"),\n",
    "    sfincs_root=\"models/sfincs_default\",\n",
    "    config=w.get_ref(\"$config.hydromt_sfincs_config\"),\n",
    "    catalog_path=w.get_ref(\"$config.catalog_path\"),\n",
    "    plot_fig=w.get_ref(\"$config.plot_fig\"),\n",
    "    subgrid_output=w.get_ref(\"$config.subgrid_output\"),\n",
    ")\n",
    "w.create_rule(sfincs_build, rule_id=\"sfincs_build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build FIAT\n",
    "\n",
    "The following method builds the FIAT model for the Acari River Basin. It takes as inputs the sfincs_build output for the model region and ground elevation, the HydroMT configuration file and the global data catalog and it generates a FIAT model saved in the models dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiat build\n",
    "# - the sfincs_build output for the model region and ground elevation\n",
    "# - settings from the hydromt_config\n",
    "# - data from the global data catalog\n",
    "\n",
    "fiat_build = fiat.FIATBuild(\n",
    "    region=sfincs_build.output.sfincs_region,\n",
    "    ground_elevation=sfincs_build.output.sfincs_subgrid_dep,\n",
    "    fiat_root=\"models/fiat_default\",\n",
    "    catalog_path=w.get_ref(\"$config.catalog_path\"),\n",
    "    config=w.get_ref(\"$config.hydromt_fiat_config\"),\n",
    ")\n",
    "w.create_rule(fiat_build, rule_id=\"fiat_build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation design events\n",
    "\n",
    "Here we derive pluvial design events from ERA5 rainfall timeseries data. First we doenload the timeseries using the `GetERA5Rainfall` method and then from the downloaded timeseries we estimate the design pluvial events for different return periods using the `PluvialDesignEvents` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Present climate events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pluvial events (get data + derive events)\n",
    "# Get ERA5 data\n",
    "pluvial_data = rainfall.GetERA5Rainfall(\n",
    "    region=sfincs_build.output.sfincs_region,\n",
    "    output_dir=Path(pwd, \"data/global-data\"),\n",
    "    start_date=w.get_ref(\"$config.start_date\"),\n",
    "    end_date=w.get_ref(\"$config.end_date\"),\n",
    ")\n",
    "w.create_rule(pluvial_data, rule_id=\"get_ERA5_data\")\n",
    "\n",
    "# Derive desing pluvial events from the downloaded (ERA5) data\n",
    "pluvial_design_events = rainfall.PluvialDesignEvents(\n",
    "    precip_nc=pluvial_data.output.precip_nc,\n",
    "    rps=w.get_ref(\"$config.rps\"),\n",
    "    wildcard=\"events\",\n",
    "    event_root=\"events/default\",\n",
    ")\n",
    "w.create_rule(pluvial_design_events, rule_id=\"derive_pluvial_design_events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future climate scenarios\n",
    "\n",
    "The pluvial design events generated in the previous step are scaled for the different climate scenarios (temperature changes; see scenarios_dict) using the `FutureClimateRainfall` method. This step produces scaled events, which are saved in the events/{scenario_name} directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climate rainfall scenarios events\n",
    "scenarios_design_events = rainfall.FutureClimateRainfall(\n",
    "    scenarios=w.get_ref(\"$config.scenarios_dict\"),\n",
    "    event_names=pluvial_design_events.params.event_names,\n",
    "    event_set_yaml=pluvial_design_events.output.event_set_yaml,\n",
    "    event_wildcard=\"events\",  # we overwrite the wildcard\n",
    "    scenario_wildcard=\"scenarios\",\n",
    "    event_root=\"events\",\n",
    ")\n",
    "w.create_rule(scenarios_design_events, rule_id=\"scenarios_pluvial_design_events\")\n",
    "\n",
    "# The produced event set is saved as follows:\n",
    "print(\"Output event sets\", scenarios_design_events.output.future_event_set_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive flood hazard\n",
    "\n",
    "In the following block, we derive the flood hazard for the different events per scenario. The hazard derivation is performed using the `SfincsUpdateForcing`, `SfincsRun`, `SfincsPostprocess`, and `SfincsDownscale` methods. First, the SFINCS forcing per event is updated using `SfincsUpdateForcing`. Then, the model execution is carried out using the `SfincsRun` method. The total number of models simulations will be equal to return periods × scenarios. The outputs of these model runs are then postprocessed. The `SfincsPostprocess` method converts SFINCS results into a regular grid of maximum water levels, which is required to update the FIAT model. The `SfincsDownscale` method then refines the SFINCS output to generate high-resolution flood hazard maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the sfincs model with pluvial events\n",
    "# This will create new SFINCS instances for each fluvial event in the simulations subfolder\n",
    "sfincs_update = sfincs.SfincsUpdateForcing(\n",
    "    sfincs_inp=sfincs_build.output.sfincs_inp,\n",
    "    event_yaml=scenarios_design_events.output.future_event_yaml,\n",
    "    output_dir=sfincs_build.output.sfincs_inp.parent / \"simulations_{scenarios}\" / \"{events}\",\n",
    ")\n",
    "w.create_rule(sfincs_update, rule_id=\"sfincs_update\")\n",
    "\n",
    "# Run the SFINCS model for each fluvial event\n",
    "# This will create simulated water levels for each pluvial event\n",
    "sfincs_run = sfincs.SfincsRun(\n",
    "    sfincs_inp=sfincs_update.output.sfincs_out_inp,\n",
    "    sfincs_exe=w.get_ref(\"$config.sfincs_exe\"),\n",
    ")\n",
    "w.create_rule(sfincs_run, rule_id=\"sfincs_run\")\n",
    "\n",
    "# Postprocesses SFINCS results to a regular grid of maximum water levels\n",
    "sfincs_post = sfincs.SfincsPostprocess(\n",
    "    sfincs_map=sfincs_run.output.sfincs_map,\n",
    ")\n",
    "w.create_rule(sfincs_post, rule_id=\"sfincs_post\")\n",
    "\n",
    "# Downscale Sfincs output to inundation maps.\n",
    "sfincs_down = sfincs.SfincsDownscale(\n",
    "    sfincs_map=sfincs_run.output.sfincs_map,\n",
    "    sfincs_subgrid_dep=sfincs_build.output.sfincs_subgrid_dep,\n",
    "    depth_min=w.get_ref(\"$config.depth_min\"),\n",
    "    output_root=\"output/hazard_{scenarios}\",\n",
    ")\n",
    "w.create_rule(sfincs_down, rule_id=\"sfincs_downscale\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive flood risk\n",
    "\n",
    "In the following block, we derive the flood risk for the different hazards per scenario produced above. The risk derivation is performed using `FIATUpdateHazard` and `FIATRun`, while then final outcome is visualized with `FIATVisualize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update hazard forcing with the pluvial eventset to compute risk\n",
    "fiat_update = fiat.FIATUpdateHazard(\n",
    "    fiat_cfg=fiat_build.output.fiat_cfg,\n",
    "    event_set_yaml=scenarios_design_events.output.future_event_set_yaml,\n",
    "    map_type=\"water_level\",\n",
    "    hazard_maps=sfincs_post.output.sfincs_zsmax,\n",
    "    risk=w.get_ref(\"$config.risk\"),\n",
    "    output_dir=fiat_build.output.fiat_cfg.parent / \"simulations_{scenarios}\",\n",
    ")\n",
    "w.create_rule(fiat_update, rule_id=\"fiat_update\")\n",
    "\n",
    "# Run FIAT\n",
    "fiat_run = fiat.FIATRun(\n",
    "    fiat_cfg=fiat_update.output.fiat_out_cfg,\n",
    "    fiat_exe=w.get_ref(\"$config.fiat_exe\"),\n",
    ")\n",
    "w.create_rule(fiat_run, rule_id=\"fiat_run\")\n",
    "\n",
    "# Visualize FIAT results\n",
    "fiat_visualize_risk = fiat.FIATVisualize(\n",
    "    fiat_output_csv=fiat_run.output.fiat_out_csv,\n",
    "    fiat_cfg=fiat_update.output.fiat_out_cfg,\n",
    "    spatial_joins_cfg=fiat_build.output.spatial_joins_cfg,\n",
    "    output_dir=\"output/risk_{scenarios}\",\n",
    ")\n",
    "w.create_rule(fiat_visualize_risk, rule_id=\"fiat_visualize_risk\")\n",
    "\n",
    "# fiat simulation folders\n",
    "print(\"fiat simulation folder:\", fiat_update.output.fiat_out_cfg.parent)\n",
    "\n",
    "# risk informetrics/infographics are stored\n",
    "print(\"risk informetrics/infographics output folder:\", fiat_visualize_risk.output.fiat_infographics.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup FloodAdapt\n",
    "\n",
    "A FloodAdapt database is created from SFINCS / Delft-FIAT models and the HydroFlows EventSet definition with the SetupFloodAdapt method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# floodadapt_build = flood_adapt.SetupFloodAdapt(\n",
    "#     sfincs_inp=sfincs_build.output.sfincs_inp,\n",
    "#     fiat_cfg=fiat_build.output.fiat_cfg,\n",
    "#     event_set_yaml=pluvial_design_events.output.event_set_yaml,\n",
    "#     output_dir=\"models/flood_adapt_builder_global_default\",\n",
    "# )\n",
    "# w.create_rule(floodadapt_build, rule_id=\"floodadapt_build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and execute the workflow\n",
    "\n",
    "The workflow can be executed using HydroFlows or a workflow engine. Below we first plot and dryrun the workflow to check if it is correctly defined. Then, we parse the workflow to SnakeMake to execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.plot_rulegraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.dryrun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to snakemake\n",
    "w.to_snakemake(f\"{name}.smk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydroflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
