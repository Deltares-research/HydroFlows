{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coastal flood risk\n",
    "\n",
    "This example shows a workflow to derive coastal flood risk using the **SFINCS** and **Delft-FIAT** models. The starting point is a user defined region and data catalog. Coastal storm tide hydrographs for different return periods are derived from the **GTSM** reanalysis dataset and used to simulate the flood hazard maps. Note that wave setup / runup are not considered. The hazard maps are combined with exposure and impact data to derive risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from pathlib import Path\n",
    "\n",
    "from hydroflows import Workflow, WorkflowConfig\n",
    "from hydroflows.log import setuplog\n",
    "from hydroflows.methods import coastal, fiat, sfincs\n",
    "from hydroflows.utils.example_data import fetch_data\n",
    "\n",
    "logger = setuplog(level=\"INFO\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define case name and root directory\n",
    "name = \"coastal_risk\"\n",
    "pwd = Path().resolve()  # Get the current file location\n",
    "case_root = Path(pwd, \"cases\", name)  # output directory\n",
    "pwd_rel = \"../../\"  # relative path from the case directory to the current file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow inputs\n",
    "\n",
    "The example requires the following inputs which are provided via a configuration file:\n",
    "- a user defined region that can be used to delineate the SFINCS model domain\n",
    "- a data catalog file describing all input datasets including the [GTSM reanalysis](https://www.deltares.nl/en/expertise/projects/global-modelling-of-tides-and-storm-surges) dataset. Here we fetch some test datasets for a region in Northern Italy. \n",
    "- HydroMT configuration files for both models.\n",
    "- model executables (docker is also possible for SFINCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the global build data\n",
    "cache_dir = fetch_data(data=\"global-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the configuration\n",
    "config = WorkflowConfig(\n",
    "    # general settings\n",
    "    region=Path(pwd_rel, \"data/build/region.geojson\"),\n",
    "    catalog_path=Path(cache_dir, \"data_catalog.yml\"),\n",
    "    plot_fig=True,\n",
    "    # sfincs settings\n",
    "    hydromt_sfincs_config=Path(pwd_rel, \"hydromt_config/sfincs_config.yml\"),\n",
    "    sfincs_exe=Path(pwd_rel, \"bin/sfincs_v2.1.1/sfincs.exe\"),\n",
    "    # fiat settings\n",
    "    hydromt_fiat_config=Path(pwd_rel, \"hydromt_config/fiat_config.yml\"),\n",
    "    fiat_exe=Path(pwd_rel, \"bin/fiat_v0.2.0/fiat.exe\"),\n",
    "    risk=True,\n",
    "    # coastal time series and design events\n",
    "    start_time=\"2014-01-01\",\n",
    "    end_time=\"2021-12-31\",\n",
    "    rps=[2, 5, 10, 50, 100],\n",
    "    # future climate SLR scenarios\n",
    "    slr_scenarios={\"present\": 0, \"rcp85_2050\": 0.2},  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow(config=config, name=name, root=case_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build models\n",
    "\n",
    "In this section we build a model cascade and make sure these are configured correctly for offline coupling, i.e. Delft-FIAT uses the same ground elevation as SFINCS. Note that you can also skip these steps and use your own models instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we build a **SFINCS** model for the user defined region using. \n",
    " - setting from the hydromt_sfincs_config, see the [HydroMT-SFINCS docs](https://deltares.github.io/hydromt_sfincs/latest/) for more info.\n",
    " - data from the catalog_path, see the [HydroMT docs](https://deltares.github.io/hydromt/v0.10.0/user_guide/data_prepare_cat.html) for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a SFINCS model\n",
    "sfincs_build = sfincs.SfincsBuild(\n",
    "    region=wf.get_ref(\"$config.region\"),\n",
    "    sfincs_root=\"models/sfincs\",\n",
    "    config=wf.get_ref(\"$config.hydromt_sfincs_config\"),\n",
    "    catalog_path=wf.get_ref(\"$config.catalog_path\"),\n",
    "    plot_fig=wf.get_ref(\"$config.plot_fig\"),\n",
    "    # save subgrid output to use in subsequent rules:\n",
    "    subgrid_output=True, \n",
    ")\n",
    "wf.create_rule(sfincs_build, rule_id=\"sfincs_build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build a **FIAT** model using:\n",
    "- the sfincs_build output for the model region and ground elevation\n",
    "- settings from the hydromt_fiat_config, see the [hydromt_fiat docs](https://deltares.github.io/hydromt_fiat/latest/)\n",
    "- data from the data catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a FIAT model\n",
    "fiat_build = fiat.FIATBuild(\n",
    "    region=sfincs_build.output.sfincs_region,\n",
    "    ground_elevation=sfincs_build.output.sfincs_subgrid_dep,\n",
    "    fiat_root=\"models/fiat\",\n",
    "    catalog_path=wf.get_ref(\"$config.catalog_path\"),\n",
    "    config=wf.get_ref(\"$config.hydromt_fiat_config\"),\n",
    ")\n",
    "wf.create_rule(fiat_build, rule_id=\"fiat_build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive coastal design events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define coastal design events for different return periods from the GTSM surge and tide timeseries data. These time series can also be replaced with observed timeseries if available. The total water level (combined tide and surge) of each event is derived by fitting an extreme value distribution to total water level peaks, using a peak-over-threshold approach. The shape of each event is derived by combining the spring tide signal with an average surge signal which is scaled to match the event total water level.\n",
    "\n",
    "Note that in case of multiple water level gauge locations this approach assumes full dependence which might be an oversimplification of the reality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the GTSM data from reanalysis data for region and time period\n",
    "get_gtsm_data = coastal.GetGTSMData(\n",
    "    gtsm_catalog=wf.get_ref(\"$config.catalog_path\"),\n",
    "    start_time=wf.get_ref(\"$config.start_time\"),\n",
    "    end_time=wf.get_ref(\"$config.end_time\"),\n",
    "    region=sfincs_build.output.sfincs_region,\n",
    "    data_root=\"data/gtsm\",\n",
    ")\n",
    "wf.create_rule(get_gtsm_data, rule_id=\"get_gtsm_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate coastal design events\n",
    "coastal_events = coastal.CoastalDesignEvents(\n",
    "    surge_timeseries=get_gtsm_data.output.surge_nc,\n",
    "    tide_timeseries=get_gtsm_data.output.tide_nc,\n",
    "    bnd_locations=get_gtsm_data.output.bnd_locations,\n",
    "    rps=wf.get_ref(\"$config.rps\"),\n",
    "    event_root=\"data/events/default\",\n",
    "    wildcard=\"event\", # wildcard to use for the pluvial events\n",
    "\n",
    ")\n",
    "\n",
    "# Note that a new \"event\" wildcard is created for the events\n",
    "wf.create_rule(coastal_events, rule_id=\"coastal_events\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The events are scaled for future climate predictions based on the a sea level rise offset. A new wildcard for scenarios is introduced develop hazard maps for each event per scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_coastal_events = coastal.FutureSLR(\n",
    "    scenarios=wf.get_ref(\"$config.slr_scenarios\"),\n",
    "    event_set_yaml=coastal_events.output.event_set_yaml,\n",
    "    event_names=coastal_events.params.event_names,\n",
    "    event_root=\"data/events\",\n",
    "    event_wildcard=\"event\",\n",
    "    scenario_wildcard=\"scenario\",\n",
    ")\n",
    "wf.create_rule(future_coastal_events, rule_id=\"future_coastal_events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive flood hazard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To derive flood hazard maps for each event, we \n",
    "1. Update the SFINCS model using the water level event timeseries. This will create new SFINCS instances for each event.\n",
    "2. Run the SFINCS model. This will create simulated water levels for each event.\n",
    "3. Postprocess the SFINCS output. This will postprocess the SFINCS results to a regular grid of maximum water levels.\n",
    "4. Optionally, downscale the SFINCS output. This will downscale the max simulated SFINCS water levels to a high-res flood depth map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the SFINCS model with pluvial events\n",
    "sfincs_update = sfincs.SfincsUpdateForcing(\n",
    "    sfincs_inp=sfincs_build.output.sfincs_inp,\n",
    "    event_yaml=future_coastal_events.output.future_event_csv,\n",
    "    output_dir=sfincs_build.output.sfincs_inp.parent/\"sim_{scenario}\"\n",
    ")\n",
    "wf.create_rule(sfincs_update, rule_id=\"sfincs_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the SFINCS model for each pluvial event\n",
    "sfincs_run = sfincs.SfincsRun(\n",
    "    sfincs_inp=sfincs_update.output.sfincs_out_inp,\n",
    "    sfincs_exe=wf.get_ref(\"$config.sfincs_exe\"),\n",
    "    run_method=\"exe\", # alternatively use \"docker\" to run in a docker container\n",
    ")\n",
    "wf.create_rule(sfincs_run, rule_id=\"sfincs_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocesses SFINCS results to a regular grid of maximum water levels\n",
    "sfincs_post = sfincs.SfincsPostprocess(\n",
    "    sfincs_map=sfincs_run.output.sfincs_map,\n",
    ")\n",
    "wf.create_rule(sfincs_post, rule_id=\"sfincs_post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downscale the SFINCS waterlevels to high-resolution water\n",
    "sfincs_downscale = sfincs.SfincsDownscale(\n",
    "    sfincs_map=sfincs_run.output.sfincs_map,\n",
    "    sfincs_subgrid_dep=sfincs_build.output.sfincs_subgrid_dep,\n",
    "    output_root=\"output/hazard/{scenario}\",\n",
    ")\n",
    "wf.create_rule(sfincs_downscale, rule_id=\"sfincs_downscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive flood risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate flood risk, we \n",
    "- Update Delft-FIAT with *all coastal events* which are combined in an event set. This will create a new Delft-FIAT instance for the event set.\n",
    "- Run Delft-FIAT to calculate flood impact and risk. This will create impact and risk data at the individual and aggregated asset level.\n",
    "- Visualize the risk results at the aggregated asset level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update FIAT hazard forcing with the pluvial eventset to compute pluvial flood risk\n",
    "fiat_update = fiat.FIATUpdateHazard(\n",
    "    fiat_cfg=fiat_build.output.fiat_cfg,\n",
    "    event_set_yaml=future_coastal_events.output.future_event_set_yaml,\n",
    "    map_type=\"water_level\",\n",
    "    hazard_maps=sfincs_post.output.sfincs_zsmax,\n",
    "    risk=wf.get_ref(\"$config.risk\"),\n",
    "    output_dir=fiat_build.output.fiat_cfg.parent/\"sim_{scenario}\",\n",
    ")\n",
    "wf.create_rule(fiat_update, rule_id=\"fiat_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FIAT to compute pluvial flood risk\n",
    "fiat_run = fiat.FIATRun(\n",
    "    fiat_cfg=fiat_update.output.fiat_out_cfg,\n",
    "    fiat_exe=wf.get_ref(\"$config.fiat_exe\"),\n",
    ")\n",
    "wf.create_rule(fiat_run, rule_id=\"fiat_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Fiat \n",
    "fiat_visualize = fiat.FIATVisualize(\n",
    "    fiat_cfg=fiat_update.output.fiat_out_cfg,\n",
    "    fiat_output_csv=fiat_run.output.fiat_out_csv,\n",
    "    spatial_joins_cfg=fiat_build.output.spatial_joins_cfg,\n",
    "    output_dir=\"output/risk/{scenario}\",\n",
    ")\n",
    "wf.create_rule(fiat_visualize, rule_id=\"fiat_visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and execute the workflow\n",
    "\n",
    "To inspect the workflow we can plot the rulegraph which shows all rules their dependencies.\n",
    "The nodes are colored based on the type, for instance the red nodes show the result rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rulegraph using graphviz\n",
    "wf.plot_rulegraph(filename=\"rulegraph.svg\", plot_rule_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dryrun workflow. Make sure no warnings are raised\n",
    "# to run the workflow in HydroFlows use wf.run(), or (preferred) use wf.to_snakemake() to create a snakemake file\n",
    "wf.dryrun()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow can be executed using HydroFlows or a workflow engine. \n",
    "To run the workflow in HydroFlows use ``wf.run()``. \n",
    "To run the workflow with SnakeMake (preferred) use ``wf.to_snakemake()`` to create a snakemake file, see below.\n",
    "You can then use the Snakemake CLI to execute the workflow, see the [snakemake documentation](https://snakemake.readthedocs.io/en/stable/executing/cli.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the workflow to a Snakefile\n",
    "wf.to_snakemake()\n",
    "\n",
    "# show the files in the case directory\n",
    "print(f\"{wf.root.relative_to(pwd)}:\")\n",
    "for f in wf.root.iterdir():\n",
    "    print(f\"- {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to run the workflow with snakemake\n",
    "# import subprocess\n",
    "# subprocess.run([\"snakemake\", \"-c\", \"1\"], cwd=wf.root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydroflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
