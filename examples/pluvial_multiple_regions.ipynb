{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large scale flood hazard (multiple regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows a workflow to derive pluvial flood hazard using the SFINCS model. The goal of the example is to show **how to scale the flood hazard to multiple model domains**. For more details about each step we refer the user to the pluvial flood risk example.\n",
    "\n",
    "This example also show how to work with parsing to CWL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from pathlib import Path\n",
    "\n",
    "from hydroflows.log import setuplog\n",
    "from hydroflows.methods import rainfall, sfincs\n",
    "from hydroflows.utils.example_data import fetch_data\n",
    "from hydroflows.workflow import Workflow, WorkflowConfig\n",
    "\n",
    "logger = setuplog(level=\"INFO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define case name and root directory\n",
    "name = \"pluvial_multiple_regions\"\n",
    "pwd = Path().resolve()  # Get the current file location\n",
    "case_root = Path(pwd, \"cases\", name)  # output directory\n",
    "pwd_rel = \"../../\"  # relative path from the case directory to the current file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the build data\n",
    "cache_dir = fetch_data(data=\"global-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the CWL runner we will be using is not supported on Windows, we will opt to run SFINCS using a docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the configuration\n",
    "config = WorkflowConfig(\n",
    "    config=Path(pwd_rel, \"hydromt_config/sfincs_config.yml\"),\n",
    "    catalog_path=Path(cache_dir, \"data_catalog.yml\"),\n",
    "    sfincs_run_method=\"docker\",\n",
    "    start_date=\"2014-01-01\",\n",
    "    end_date=\"2021-12-31\",\n",
    "    # sfincs settings\n",
    "    hydromt_sfincs_config=Path(pwd_rel, \"hydromt_config/sfincs_config.yml\"),\n",
    "    subgrid_output=True,\n",
    "    # design event settings\n",
    "    rps=[2, 5, 10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the workflow\n",
    "\n",
    "Note that we initialize the workflow with a region wildcard to create flood hazard for multiple regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the workflow\n",
    "wf = Workflow(\n",
    "    config=config,\n",
    "    wildcards={\"region\": [\"region\", \"region2\"]},\n",
    "    name=name,\n",
    "    root=case_root,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build models\n",
    "\n",
    "In this section we build SFINCS models for multiple regions. Note that we use the ``{region}`` wildcard on the in- and outputs of each method. The method will be executed for each input region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the SFINCS models\n",
    "sfincs_build = sfincs.SfincsBuild(\n",
    "    region=Path(pwd_rel, \"data/build/{region}.geojson\"),  # input region\n",
    "    sfincs_root=\"models/sfincs/{region}\",  # output model directory\n",
    "    config=wf.get_ref(\"$config.hydromt_sfincs_config\"),\n",
    "    catalog_path=wf.get_ref(\"$config.catalog_path\"),\n",
    "    subgrid_output=wf.get_ref(\"$config.subgrid_output\"),\n",
    "    )\n",
    "wf.create_rule(sfincs_build, \"sfincs_build\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive pluvial design events\n",
    "\n",
    "In contrast to the pluvial risk workflow, we will name the the `event_root` param \"events/{region}_events\". This way we avoid the following conflict when parsing to CWL. The outputs of both the `pluvial_events` rule and the `sfincs_build` rule will be used as inputs to the `sfincs_update` rule. If we were to follow the naming as the pluvial risk example, the `pluvial_events` and `sfincs_build` rules will create output directory with \"{region}\" as stem. Since CWL will flatten the rest of those output directory paths, the `sfincs_update` rule will receive two input directories both named \"{region}\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pluvial_events = rainfall.PluvialDesignEventsGPEX(\n",
    "    gpex_nc=Path(cache_dir, \"gpex.nc\"),  \n",
    "    region=sfincs_build.output.sfincs_region,\n",
    "    event_root=\"events/{region}_events\",\n",
    "    rps=wf.get_ref(\"$config.rps\"),\n",
    "    wildcard=\"events\", # wildcard to use for the pluvial events\n",
    ")\n",
    "\n",
    "# Note that a new \"events\" wildcard is created for the events\n",
    "wf.create_rule(pluvial_events, rule_id=\"pluvial_events\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive flood hazard\n",
    "\n",
    "Here we have to set the `copy_model` param of the `sfincs_update` rule to `True`. The flattening of input file paths by CWL we encountered earlier does not work well with the relative paths the model config files will be using when `copy_model` is set to `False`.\n",
    "\n",
    "Note also that in the `sfincs_run` rule we use the `run_method` param instead of the `sfincs_exe` param to indicate that we will be using the docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the SFINCS models\n",
    "sfincs_update = sfincs.SfincsUpdateForcing(\n",
    "    sfincs_inp=sfincs_build.output.sfincs_inp,\n",
    "    event_yaml=pluvial_events.output.event_yaml,\n",
    "    output_dir=sfincs_build.output.sfincs_inp.parent/\"simulations\"/\"{events}\",\n",
    "    copy_model=True,\n",
    ")\n",
    "wf.create_rule(sfincs_update, rule_id=\"sfincs_update\")\n",
    "\n",
    "# Run SFINCS model\n",
    "sfincs_run = sfincs.SfincsRun(\n",
    "    sfincs_inp=sfincs_update.output.sfincs_out_inp,\n",
    "    run_method=wf.get_ref(\"$config.sfincs_run_method\"),\n",
    ")\n",
    "wf.create_rule(sfincs_run, rule_id=\"sfincs_run\")\n",
    "\n",
    "# Downscale the SFINCS waterlevels to high-resolution water\n",
    "sfincs_downscale = sfincs.SfincsDownscale(\n",
    "    sfincs_map=sfincs_run.output.sfincs_map,\n",
    "    sfincs_subgrid_dep=sfincs_build.output.sfincs_subgrid_dep,\n",
    "    output_root=\"output/hazard/{region}\",\n",
    ")\n",
    "wf.create_rule(sfincs_downscale, \"sfincs_downscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and execute the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rulegraph using graphviz\n",
    "wf.plot_rulegraph(filename=\"rulegraph.svg\", plot_rule_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a dry run of the workflow\n",
    "wf.dryrun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the workflow to a Snakefile and snakefile.config.yml\n",
    "wf.to_snakemake()\n",
    "\n",
    "# show the files in the case directory\n",
    "print(f\"{wf.root.relative_to(pwd)}:\")\n",
    "for f in wf.root.iterdir():\n",
    "    print(f\"- {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to run the workflow with snakemake\n",
    "# import subprocess\n",
    "# subprocess.run([\"snakemake\", \"-c\", \"1\"], cwd=wf.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the workflow to a cwl file and cwl config file\n",
    "wf.to_cwl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to run the workflow with cwll\n",
    "# import subprocess\n",
    "# subprocess.run([\"cwltool\", \"pluvial_multiple_regions.cwl\", \"pluvial_multiple_regions.config.yml\"], cwd=wf.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
