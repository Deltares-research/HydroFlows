{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pluvial flood risk\n",
    "\n",
    "This example shows a workflow to derive pluvial flood risk using the **SFINCS** and **Delft-FIAT** models. The starting point is a user defined region and data catalog. Rainfall IDF curves from the GPEX dataset are translated into design events (hyetographs) for different return periods and used to simulate the flood hazard maps. The hazard maps are combined with exposure and impact data to derive risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and setup logging\n",
    "from pathlib import Path\n",
    "\n",
    "from hydroflows import Workflow, WorkflowConfig\n",
    "from hydroflows.log import setuplog\n",
    "from hydroflows.methods import fiat, flood_adapt, rainfall, sfincs\n",
    "from hydroflows.utils.example_data import fetch_data\n",
    "\n",
    "logger = setuplog(level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General setup of workflow\n",
    "name = \"pluvial_risk\"\n",
    "pwd = Path().resolve()  # Get the current file location\n",
    "case_root = Path(pwd, \"cases\", name)  # output directory\n",
    "pwd_rel = \"../../\"  # relative path from the case directory to the current file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow inputs\n",
    "\n",
    "The example requires the following inputs which are provided via a configuration file:\n",
    "- a user defined region that can be used to delineate the SFINCS model domain\n",
    "- a data catalog file describing all input datasets. Here we fetch some test datasets for a region in Northern Italy.  \n",
    "- The [GPEX IDF dataset](https://data.4tu.nl/articles/dataset/GPEX_Global_Precipitation_EXtremes/12764429/4). Note that rainfall timeseries data can also be used to derive design events.\n",
    "- HydroMT configuration files for both models\n",
    "- model executables (docker is also possible for SFINCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the test global-data data catalog  \n",
    "cache_dir = fetch_data(data=\"global-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the config file\n",
    "config = WorkflowConfig(\n",
    "    # general settings\n",
    "    region=Path(pwd_rel, \"data/build/region.geojson\"),\n",
    "    catalog_path=Path(cache_dir, \"data_catalog.yml\"),\n",
    "    plot_fig=True,\n",
    "    # sfincs settings\n",
    "    hydromt_sfincs_config=Path(pwd_rel, \"hydromt_config/sfincs_config.yml\"),\n",
    "    sfincs_exe=Path(pwd_rel, \"bin/sfincs_v2.1.1/sfincs.exe\"),\n",
    "    # fiat settings\n",
    "    hydromt_fiat_config=Path(pwd_rel, \"hydromt_config/fiat_config.yml\"),\n",
    "    fiat_exe=Path(pwd_rel, \"bin/fiat_v0.2.0/fiat.exe\"),\n",
    "    risk=True,\n",
    "    # rainfall and design events settings\n",
    "    start_date=\"2000-01-01\",\n",
    "    end_date=\"2021-12-31\",\n",
    "    rps=[2, 5, 10, 50, 100],\n",
    "    # delta temp climate scenarios\n",
    "    dt_scenarios={\"present\": 0, \"rcp85_2050\": 1.5},  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and empty workflow\n",
    "wf = Workflow(name=name, config=config, root=case_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build models\n",
    "\n",
    "In this section we build a model cascade and make sure these are configured correctly for offline coupling, i.e. Delft-FIAT uses the same ground elevation as SFINCS. Note that you can also skip these steps and use your own models instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we build a **SFINCS** model for the user defined region using. \n",
    " - setting from the hydromt_sfincs_config, see the [HydroMT-SFINCS docs](https://deltares.github.io/hydromt_sfincs/latest/) for more info.\n",
    " - data from the catalog_path, see the [HydroMT docs](https://deltares.github.io/hydromt/v0.10.0/user_guide/data_prepare_cat.html) for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a SFINCS model\n",
    "sfincs_build = sfincs.SfincsBuild(\n",
    "    region=wf.get_ref(\"$config.region\"),\n",
    "    sfincs_root=\"models/sfincs\",\n",
    "    config=wf.get_ref(\"$config.hydromt_sfincs_config\"),\n",
    "    catalog_path=wf.get_ref(\"$config.catalog_path\"),\n",
    "    plot_fig=wf.get_ref(\"$config.plot_fig\"),\n",
    "    subgrid_output=True,  # save subgrid output for subsequent methods\n",
    ")\n",
    "wf.create_rule(sfincs_build, rule_id=\"sfincs_build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build a **FIAT** model using:\n",
    "- the sfincs_build output for the model region and ground elevation\n",
    "- settings from the hydromt_fiat_config, see the [hydromt_fiat docs](https://deltares.github.io/hydromt_fiat/latest/)\n",
    "- data from the data catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Delft-FIAT model\n",
    "fiat_build = fiat.FIATBuild(\n",
    "    region=sfincs_build.output.sfincs_region,\n",
    "    ground_elevation=sfincs_build.output.sfincs_subgrid_dep,\n",
    "    fiat_root=\"models/fiat\",\n",
    "    catalog_path=wf.get_ref(\"$config.catalog_path\"),\n",
    "    config=wf.get_ref(\"$config.hydromt_fiat_config\"),\n",
    ")\n",
    "wf.create_rule(fiat_build, rule_id=\"fiat_build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive pluvial design events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define pluvial design events from GPEX IDF data using the alternating block method.\n",
    "We derive the IDF curves for the centroid of the SFINCS model region.\n",
    "Alternatively, you can use the `PluvialDesignEvents` class to define pluvial events from a rainfall time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pluvial_events = rainfall.PluvialDesignEventsGPEX(\n",
    "    gpex_nc=Path(cache_dir, \"gpex.nc\"),  \n",
    "    region=sfincs_build.output.sfincs_region,\n",
    "    event_root=\"data/events/default\",\n",
    "    rps=wf.get_ref(\"$config.rps\"),\n",
    "    wildcard=\"events\", # wildcard to use for the pluvial events\n",
    ")\n",
    "\n",
    "# Note that a new \"events\" wildcard is created for the events\n",
    "wf.create_rule(pluvial_events, rule_id=\"pluvial_events\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The events are scaled for future climate predictions based on the Clausius-Clapeyron relation. A new wildcard for scenarios is introduced develop hazard maps for each event per scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_pluvial_events = rainfall.FutureClimateRainfall(\n",
    "    scenarios=wf.get_ref(\"$config.dt_scenarios\"),\n",
    "    event_set_yaml=pluvial_events.output.event_set_yaml,\n",
    "    event_names=pluvial_events.params.event_names,\n",
    "    event_root=\"data/events\",\n",
    "    event_wildcard=\"event\",\n",
    "    scenario_wildcard=\"scenario\",\n",
    ")\n",
    "wf.create_rule(future_pluvial_events, rule_id=\"future_pluvial_events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive flood hazard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To derive flood hazard maps for each event, we \n",
    "1. Update the SFINCS model using the rainfall event timeseries. This will create new SFINCS instances for each event.\n",
    "2. Run the SFINCS model. This will create simulated water levels for each event.\n",
    "3. Postprocess the SFINCS output. This will postprocess the SFINCS results to a regular grid of maximum water levels.\n",
    "4. Optionally, downscale the SFINCS output. This will downscale the max simulated SFINCS water levels to a high-res flood depth map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the SFINCS model with pluvial events\n",
    "sfincs_update = sfincs.SfincsUpdateForcing(\n",
    "    sfincs_inp=sfincs_build.output.sfincs_inp,\n",
    "    event_yaml=future_pluvial_events.output.future_event_yaml,\n",
    "    output_dir=sfincs_build.output.sfincs_inp.parent/\"sim_{scenario}\"\n",
    ")\n",
    "wf.create_rule(sfincs_update, rule_id=\"sfincs_update\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the SFINCS model for each pluvial event\n",
    "sfincs_run = sfincs.SfincsRun(\n",
    "    sfincs_inp=sfincs_update.output.sfincs_out_inp,\n",
    "    sfincs_exe=wf.get_ref(\"$config.sfincs_exe\"),\n",
    "    run_method=\"exe\", # alternatively use \"docker\" to run in a docker container\n",
    ")\n",
    "wf.create_rule(sfincs_run, rule_id=\"sfincs_run\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocesses SFINCS results\n",
    "sfincs_post = sfincs.SfincsPostprocess(\n",
    "    sfincs_map=sfincs_run.output.sfincs_map,\n",
    "    output_root=sfincs_run.output.sfincs_map.parent\n",
    ")\n",
    "wf.create_rule(sfincs_post, rule_id=\"sfincs_post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downscale the SFINCS waterlevels to high-resolution water\n",
    "sfincs_downscale = sfincs.SfincsDownscale(\n",
    "    sfincs_map=sfincs_run.output.sfincs_map,\n",
    "    sfincs_subgrid_dep=sfincs_build.output.sfincs_subgrid_dep,\n",
    "    output_root=\"output/hazard/{scenario}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive flood risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate flood risk, we \n",
    "- Update Delft-FIAT with *all pluvial events* which are combined in an event set. This will create a new Delft-FIAT instance for the event set.\n",
    "- Run Delft-FIAT to calculate flood impact and risk. This will create impact and risk data at the individual and aggregated asset level.\n",
    "- Visualize the risk results at the aggregated asset level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update FIAT hazard forcing with the pluvial eventset to compute pluvial flood risk\n",
    "fiat_update = fiat.FIATUpdateHazard(\n",
    "    fiat_cfg=fiat_build.output.fiat_cfg,\n",
    "    event_set_yaml=future_pluvial_events.output.future_event_set_yaml,\n",
    "    map_type=\"water_level\",\n",
    "    hazard_maps=sfincs_post.output.sfincs_zsmax,\n",
    "    risk=wf.get_ref(\"$config.risk\"),\n",
    "    output_dir=fiat_build.output.fiat_cfg.parent/\"sim_{scenario}\"\n",
    ")\n",
    "wf.create_rule(fiat_update, rule_id=\"fiat_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FIAT to compute pluvial flood risk\n",
    "fiat_run = fiat.FIATRun(\n",
    "    fiat_cfg=fiat_update.output.fiat_out_cfg,\n",
    "    fiat_exe=wf.get_ref(\"$config.fiat_exe\"),\n",
    "    run_method=\"exe\", \n",
    ")\n",
    "wf.create_rule(fiat_run, rule_id=\"fiat_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Fiat \n",
    "fiat_visualize = fiat.FIATVisualize(\n",
    "    fiat_cfg=fiat_update.output.fiat_out_cfg,\n",
    "    fiat_output_csv=fiat_run.output.fiat_out_csv,\n",
    "    spatial_joins_cfg=fiat_build.output.spatial_joins_cfg, # aggregation level for visualization\n",
    "    output_dir=\"output/risk/{scenario}\",\n",
    ")\n",
    "wf.create_rule(fiat_visualize, rule_id=\"fiat_visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare FloodAdapt database input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, a FloodAdapt instance can be created using the SFINCS and Delft-FIAT models and the derived pluvial event set.\n",
    "The `SetupFloodAdapt` method prepares the models and a configuration file which can readily be used by the FloodAdapt database builder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Prepare Sfincs Models for FloodAdapt\n",
    "prep_sfincs_run = flood_adapt.PrepSfincsModels(\n",
    "    sfincs_inp=sfincs_build.output.sfincs_inp,\n",
    ")\n",
    "wf.create_rule(prep_sfincs_run, rule_id=\"prep_sfincs_model\")\n",
    "\n",
    "# %% Prepare FloodAdapt\n",
    "setup_floodadapt = flood_adapt.SetupFloodAdapt(\n",
    "    fiat_cfg=fiat_build.output.fiat_cfg,\n",
    "    sfincs_inp=prep_sfincs_run.output.sfincs_out_inp,\n",
    "    db_name= \"Pluvial_risk\",\n",
    "    description= \"This is a pluvial risk event set database\",\n",
    "    event_set_yaml=pluvial_events.output.event_set_yaml,\n",
    "    output_dir=Path(\"output/floodadapt\"),\n",
    ")\n",
    "wf.create_rule(setup_floodadapt, rule_id=\"setup_floodadapt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and execute the workflow\n",
    "\n",
    "To inspect the workflow we can plot the rulegraph which shows all rules their dependencies.\n",
    "The nodes are colored based on the type, for instance the red nodes show the result rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rulegraph using graphviz\n",
    "wf.plot_rulegraph(filename=\"rulegraph.svg\", plot_rule_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dryrun workflow. Make sure no warnings are raised\n",
    "wf.dryrun()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow can be executed using HydroFlows or a workflow engine. \n",
    "To run the workflow in HydroFlows use ``wf.run()``. \n",
    "To run the workflow with SnakeMake (preferred) use ``wf.to_snakemake()`` to create a snakemake file, see below.\n",
    "You can then use the Snakemake CLI to execute the workflow, see the [snakemake documentation](https://snakemake.readthedocs.io/en/stable/executing/cli.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the workflow to a Snakefile\n",
    "wf.to_snakemake()\n",
    "\n",
    "# show the files in the case directory\n",
    "print(f\"{wf.root.relative_to(pwd)}:\")\n",
    "for f in wf.root.iterdir():\n",
    "    if f.is_file():\n",
    "        print(f\"- {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to run the workflow with snakemake\n",
    "# import subprocess\n",
    "# subprocess.run([\"snakemake\", \"-c\", \"1\"], cwd=wf.root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydroflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
